# Практическая работа №9: Распределенная обработка данных с MPI

## Что это такое простыми словами

Эта практическая работа учит работать с параллельными вычислениями - когда одну большую задачу делят на маленькие части и решают одновременно на разных процессорах. Это как если бы вы раздали задачи нескольким друзьям, и все делали свою часть параллельно, а потом собрали результаты вместе.

MPI (Message Passing Interface) - это система, которая позволяет разным процессам (программам) общаться между собой и обмениваться данными.

## Описание заданий

### Задание 1: Вычисление среднего и стандартного отклонения
**Что делаем:**
- Создаем большой массив из миллиона случайных чисел
- Делим этот массив между несколькими процессами
- Каждый процесс считает сумму и сумму квадратов своей части
- Собираем все суммы вместе и вычисляем среднее значение и разброс данных

**Зачем это нужно:**
Показывает, как распределять данные между процессами и собирать результаты обратно. Полезно для анализа больших наборов данных.

### Задание 2: Решение системы уравнений методом Гаусса
**Что делаем:**
- Создаем систему линейных уравнений (много уравнений с много неизвестными)
- Делим строки матрицы между процессами
- Каждый процесс обрабатывает свои строки
- В конце получаем решение - значения всех неизвестных

**Зачем это нужно:**
Метод Гаусса используется везде - в физике, экономике, машинном обучении. Параллельная версия позволяет решать огромные системы быстрее.

### Задание 3: Поиск кратчайших путей в графе (алгоритм Флойда-Уоршелла)
**Что делаем:**
- Создаем граф (сеть точек, соединенных линиями с весами)
- Находим самые короткие пути между всеми парами точек
- Каждый процесс обрабатывает свою часть графа

**Зачем это нужно:**
Находит применение в навигации (GPS), сетевой маршрутизации, планировании логистики. Параллельная версия работает быстрее на больших картах.

## Как компилировать и запускать

### Компиляция всех программ:
```bash
make all
```

### Или компиляция отдельных программ:
```bash
mpic++ task1.cpp -o task1
mpic++ task2.cpp -o task2
mpic++ task3.cpp -o task3
```

### Запуск программ (например, на 4 процессах):
```bash
mpirun -np 4 ./task1
mpirun -np 4 ./task2
mpirun -np 4 ./task3
```

### Или через Makefile:
```bash
make run1  # запуск задания 1
make run2  # запуск задания 2
make run3  # запуск задания 3
```

### Очистка скомпилированных файлов:
```bash
make clean
```

## Что измеряем

Для каждой программы измеряется время выполнения. Можно запустить с разным количеством процессов (2, 4, 8 и т.д.) и посмотреть, как меняется скорость работы.

Пример:
```bash
mpirun -np 2 ./task1   # с 2 процессами
mpirun -np 4 ./task1   # с 4 процессами
mpirun -np 8 ./task1   # с 8 процессами
```

## Основные функции MPI, используемые в программах

- **MPI_Init** - запуск MPI окружения
- **MPI_Comm_size** - узнать, сколько всего процессов
- **MPI_Comm_rank** - узнать номер текущего процесса
- **MPI_Scatterv** - раздать данные от главного процесса всем остальным (с учетом разных размеров)
- **MPI_Scatter** - раздать данные равными частями
- **MPI_Gather** - собрать данные от всех процессов на главном
- **MPI_Reduce** - собрать данные и применить операцию (например, сложение)
- **MPI_Bcast** - разослать данные от одного процесса всем остальным
- **MPI_Wtime** - измерить время
- **MPI_Finalize** - завершить работу MPI

## Структура кода

Все программы следуют общей логике:
1. Инициализация MPI
2. Главный процесс создает данные
3. Данные распределяются между процессами
4. Каждый процесс обрабатывает свою часть
5. Результаты собираются на главном процессе
6. Главный процесс выводит результаты
7. Завершение работы MPI
