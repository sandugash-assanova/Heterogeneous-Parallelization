ОПИСАНИЕ БЛОК-СХЕМ
Практическая работа по гетерогенной параллелизации на CUDA



1. Генерация и подготовка данных
   └─ Создание массива случайных чисел
   └─ Сохранение в файл для повторного использования

2. Выделение памяти
   └─ Выделение памяти на CPU (host)
   └─ Выделение памяти на GPU (device) через cudaMalloc()

3. Передача данных на GPU
   └─ Копирование с CPU на GPU через cudaMemcpy(HostToDevice)

4. Выбор алгоритма (ромб - точка принятия решения)
   └─ Редукция с глобальной памятью
   └─ Редукция с разделяемой памятью
   └─ Сортировка на GPU

5. Выполнение на GPU
   └─ Запуск kernel функций
   └─ Параллельная обработка данных

6. Получение результатов
   └─ Копирование с GPU на CPU через cudaMemcpy(DeviceToHost)

7. Проверка и измерение
   └─ Проверка корректности результатов
   └─ Измерение времени выполнения

8. Очистка ресурсов
   └─ Освобождение памяти GPU через cudaFree()
   └─ Освобождение памяти CPU

ОБОЗНАЧЕНИЯ НА СХЕМЕ:

• Овал (зеленый) - начало программы
• Прямоугольник - процесс или операция
• Ромб (желтый) - условие или выбор
• Овал (красный) - конец программы
• Стрелки - направление выполнения программы

═══════════════════════════════════════════════════════════════════════════════

2. ДЕТАЛЬНАЯ СХЕМА РЕДУКЦИИ (flowchart_reduction.png / flowchart_reduction.svg)

Эта схема детально показывает работу kernel функции reduceSharedMemory -
самого эффективного алгоритма редукции с использованием разделяемой памяти.

ЭТАПЫ РАБОТЫ KERNEL:

ЭТАП 1: ИНИЦИАЛИЗАЦИЯ И ЗАГРУЗКА
├─ Вычисление индексов потока (tid, глобальный индекс i)
├─ Выделение разделяемой памяти __shared__ sdata[256]
└─ Загрузка данных из глобальной памяти в разделяемую
   • Если i < size: загружаем реальные данные
   • Если i >= size: заполняем нулями

ЭТАП 2: ПЕРВАЯ СИНХРОНИЗАЦИЯ
└─ __syncthreads() - все потоки ждут завершения загрузки
   Это критически важно! Иначе некоторые потоки начнут работу
   с неинициализированными данными.

ЭТАП 3: ЦИКЛ РЕДУКЦИИ (попарное суммирование)
├─ Начальное значение stride: s = blockDim.x / 2 (обычно 128)
└─ На каждой итерации:
   ├─ Проверка: поток активен? (tid < s)
   ├─ Если да: суммируем пару элементов sdata[tid] += sdata[tid + s]
   ├─ Если нет: поток ждет (неактивен)
   ├─ __syncthreads() - синхронизация после суммирования
   └─ Уменьшаем stride вдвое: s = s / 2

Пример для 8 элементов [a,b,c,d,e,f,g,h]:
• Итерация 1 (s=4): потоки 0-3 активны
  └─ [a+e, b+f, c+g, d+h, -, -, -, -]
• Итерация 2 (s=2): потоки 0-1 активны
  └─ [a+e+c+g, b+f+d+h, -, -, -, -, -, -]
• Итерация 3 (s=1): поток 0 активен
  └─ [a+b+c+d+e+f+g+h, -, -, -, -, -, -, -]

ЭТАП 4: ЗАПИСЬ РЕЗУЛЬТАТА
└─ Только первый поток (tid == 0) записывает результат
   └─ output[blockIdx.x] = sdata[0]
   └─ Это сумма всех элементов блока

ПОЧЕМУ ЭТО ЭФФЕКТИВНО:

• Разделяемая память в ~100 раз быстрее глобальной
• Данные читаются из глобальной памяти только один раз
• Все вычисления идут с быстрой разделяемой памятью
• В глобальную память пишем только один раз в конце
• Синхронизация позволяет потокам безопасно обмениваться данными

═══════════════════════════════════════════════════════════════════════════════

3. СХЕМА СРАВНЕНИЯ ПРОИЗВОДИТЕЛЬНОСТИ (flowchart_comparison.png / flowchart_comparison.svg)

Эта схема наглядно показывает разницу между двумя подходами к редукции.

ПУТЬ 1: ГЛОБАЛЬНАЯ ПАМЯТЬ (медленный)

Входные данные → Глобальная память
├─ ШАГ 1: Чтение из глобальной памяти
│  └─ Задержка: ~400 тактов процессора
│  └─ Происходит множество раз
│
├─ ШАГ 2: Вычисления в регистрах
│  └─ Быстро, но между ними постоянные обращения к памяти
│
├─ ШАГ 3: Запись в глобальную память
│  └─ Задержка: ~400 тактов
│  └─ Происходит для каждого потока
│
└─ РЕЗУЛЬТАТ: ~2.5 мс для 1,000,000 элементов

ПУТЬ 2: РАЗДЕЛЯЕМАЯ ПАМЯТЬ (быстрый)

Входные данные → Разделяемая память
├─ ШАГ 1: Одноразовая загрузка
│  └─ Читаем из глобальной памяти ОДИН РАЗ
│  └─ Загружаем в разделяемую память блока
│
├─ ШАГ 2: Работа с разделяемой памятью
│  └─ Задержка: ~4 такта (в 100 раз быстрее!)
│  └─ Все вычисления идут с быстрой памятью
│
├─ ШАГ 3: Синхронизация потоков
│  └─ __syncthreads() координирует работу
│  └─ Циклическая редукция с синхронизацией
│
├─ ШАГ 4: Одноразовая запись
│  └─ Пишем в глобальную память ОДИН РАЗ
│  └─ Только итоговый результат блока
│
└─ РЕЗУЛЬТАТ: ~0.8 мс для 1,000,000 элементов

СРАВНЕНИЕ:

                    Глобальная    Разделяемая    Выигрыш
Размер 10K         0.15 мс       0.05 мс        3x
Размер 100K        1.2 мс        0.4 мс         3x
Размер 1M          2.5 мс        0.8 мс         3x

УСКОРЕНИЕ: ~3x раз быстрее!

ПОЧЕМУ РАЗДЕЛЯЕМАЯ ПАМЯТЬ БЫСТРЕЕ:

1. Меньше обращений к медленной глобальной памяти
   • Глобальная: N чтений + N записей = 2N операций
   • Разделяемая: N чтений + 1 запись + внутренняя работа

2. Разделяемая память физически ближе к вычислительным ядрам
   • Находится на том же чипе что и процессоры
   • Глобальная память - отдельный чип через шину

3. Параллельный доступ к разделяемой памяти
   • Множество банков памяти работают параллельно
   • Глобальная память имеет последовательный доступ

4. Меньше конфликтов доступа
   • Разделяемая память используется внутри блока
   • Глобальная память - общий ресурс для всех блоков

═══════════════════════════════════════════════════════════════════════════════

ИНТЕРПРЕТАЦИЯ БЛОК-СХЕМ

При анализе блок-схем обратите внимание на:

1. РОМБЫ (условные операторы)
   • Точки принятия решений
   • Ветвление алгоритма
   • Условия окончания циклов

2. ЦИКЛЫ
   • Обратные стрелки к предыдущим блокам
   • Условие выхода из цикла
   • Количество итераций

3. СИНХРОНИЗАЦИЯ
   • Блоки с __syncthreads()
   • Критические точки где потоки должны подождать друг друга
   • Необходимы для корректной работы параллельного кода

4. РАБОТА С ПАМЯТЬЮ
   • Выделение (Malloc)
   • Копирование (Memcpy)
   • Освобождение (Free)
   • Переходы между типами памяти

5. ПАРАЛЛЕЛИЗМ
   • Операции выполняются одновременно разными потоками
   • На схеме не показана явно, но подразумевается в kernel
   • Ключевое преимущество GPU архитектуры

═══════════════════════════════════════════════════════════════════════════════

ИСПОЛЬЗОВАНИЕ БЛОК-СХЕМ В ОТЧЕТЕ

Рекомендации по включению схем в отчет:

1. Общая схема (flowchart.png)
   └─ Используйте для объяснения общей структуры программы
   └─ Покажите последовательность выполнения задач

2. Схема редукции (flowchart_reduction.png)
   └─ Детальное объяснение самого сложного алгоритма
   └─ Демонстрация работы с разделяемой памятью
   └─ Объяснение синхронизации потоков

3. Схема сравнения (flowchart_comparison.png)
   └─ Наглядное сравнение двух подходов
   └─ Объяснение причин разницы в производительности
   └─ Иллюстрация к результатам измерений

Все схемы доступны в двух форматах:
• PNG - для вставки в Word документы и презентации
• SVG - векторный формат для масштабирования без потери качества

═══════════════════════════════════════════════════════════════════════════════
